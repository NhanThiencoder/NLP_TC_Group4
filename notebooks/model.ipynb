{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d93f384",
   "metadata": {},
   "source": [
    "# üß† NLP Project: Local Benchmark (PyCharm)\n",
    "\n",
    "Notebook n√†y ƒë∆∞·ª£c t·ªëi ∆∞u ƒë·ªÉ ch·∫°y tr√™n **M√°y t√≠nh c√° nh√¢n (Local PC)** th√¥ng qua PyCharm.\n",
    "\n",
    "### üõ†Ô∏è ƒê√£ s·ª≠a l·ªói:\n",
    "1.  **Fix IProgress**: Chuy·ªÉn sang d√πng `tqdm` b·∫£n chu·∫©n (text-based) ƒë·ªÉ kh√¥ng c·∫ßn `ipywidgets`.\n",
    "2.  **Fix LSTM Warning**: B·ªè `dropout` trong LSTM layer v√¨ ch·ªâ d√πng 1 l·ªõp (num_layers=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecb68e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒêang ch·∫°y tr√™n: cuda\n",
      "   ‚û§ Card ƒë·ªì h·ªça: NVIDIA GeForce RTX 5070 Ti Laptop GPU\n",
      "üìÇ Data path: c:\\Users\\ASUS\\Programming-Coding\\Python\\NLM\\NLP_TC_Group4\\data\\final\n",
      "üìÇ Report path: c:\\Users\\ASUS\\Programming-Coding\\Python\\NLM\\NLP_TC_Group4\\reports\n"
     ]
    }
   ],
   "source": [
    "# --- 1. SETUP & IMPORTS ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from tqdm import tqdm \n",
    "\n",
    "# SKLEARN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# DEEP LEARNING\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW \n",
    "\n",
    "# --- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N LOCAL (PC C·ª¶A B·∫†N) ---\n",
    "# ƒê∆∞·ªùng d·∫´n g·ªëc d·ª± √°n\n",
    "CURRENT_DIR = Path.cwd()\n",
    "\n",
    "# Ki·ªÉm tra xem folder data n·∫±m ngay ƒë√¢y hay n·∫±m ·ªü th∆∞ m·ª•c cha\n",
    "if (CURRENT_DIR / \"data\").exists():\n",
    "    PROJECT_ROOT = CURRENT_DIR\n",
    "elif (CURRENT_DIR.parent / \"data\").exists():\n",
    "    PROJECT_ROOT = CURRENT_DIR.parent\n",
    "else:\n",
    "    PROJECT_ROOT = CURRENT_DIR\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"final\"\n",
    "JSONL_PATH = DATA_DIR / \"nlp_dataset.jsonl\"\n",
    "REPORT_DIR = PROJECT_ROOT / \"reports\"\n",
    "MODEL_DIR = PROJECT_ROOT / \"models\"\n",
    "\n",
    "# T·∫°o folder b√°o c√°o n·∫øu ch∆∞a c√≥\n",
    "REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Ki·ªÉm tra thi·∫øt b·ªã (GPU/CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"‚úÖ ƒêang ch·∫°y tr√™n: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"   ‚û§ Card ƒë·ªì h·ªça: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è ƒêang ch·∫°y tr√™n CPU (S·∫Ω ch·∫≠m h∆°n GPU).\")\n",
    "\n",
    "print(f\"üìÇ Data path: {DATA_DIR}\")\n",
    "print(f\"üìÇ Report path: {REPORT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9da8621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ ƒêang t·∫£i d·ªØ li·ªáu...\n",
      "   ƒê·ªçc th·ª≠ file cache: c:\\Users\\ASUS\\Programming-Coding\\Python\\NLM\\NLP_TC_Group4\\data\\final\\nlp_dataset.jsonl\n",
      "‚ö†Ô∏è File c≈© thi·∫øu c·ªôt 'raw_text' (c·∫ßn cho PhoBERT). ƒêang x√≥a ƒë·ªÉ t·∫°o l·∫°i...\n",
      "   ƒêang qu√©t t·ª´ folder data (l·∫ßn ƒë·∫ßu s·∫Ω h∆°i l√¢u)...\n",
      "   T√¨m th·∫•y 0 file vƒÉn b·∫£n.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ t·∫°o file dataset m·ªõi ƒë·∫ßy ƒë·ªß c·ªôt.\n",
      "üìä T·ªïng s·ªë b√†i: 0\n",
      "üëÄ C√°c c·ªôt hi·ªán c√≥: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'label_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 93\u001b[39m\n\u001b[32m     91\u001b[39m target_col = \u001b[33m'\u001b[39m\u001b[33mlabel_name\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     92\u001b[39m le = LabelEncoder()\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mlabel_id\u001b[39m\u001b[33m'\u001b[39m] = le.fit_transform(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m     94\u001b[39m num_classes = \u001b[38;5;28mlen\u001b[39m(le.classes_)\n\u001b[32m     96\u001b[39m train_df, test_df = train_test_split(df, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m, stratify=df[target_col])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\anaconda3\\envs\\trading\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\anaconda3\\envs\\trading\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[39m, in \u001b[36mRangeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    415\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[32m    418\u001b[39m \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'label_name'"
     ]
    }
   ],
   "source": [
    "# --- 2. LOAD DATA (X·ª¨ L√ù CHU·∫®N CHO FILE JSONL C·ª¶A B·∫†N) ---\n",
    "from pyvi import ViTokenizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import unicodedata\n",
    "import os\n",
    "\n",
    "# C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n\n",
    "CURRENT_DIR = Path.cwd()\n",
    "if (CURRENT_DIR / \"data\").exists():\n",
    "    DATA_DIR = CURRENT_DIR / \"data\" / \"final\"\n",
    "else:\n",
    "    DATA_DIR = CURRENT_DIR \n",
    "\n",
    "JSONL_PATH = DATA_DIR / \"nlp_dataset.jsonl\"\n",
    "\n",
    "# Danh s√°ch Stopwords (ƒê√£ c·∫≠p nh·∫≠t t·ª´ EDA + T·ª´ ph·ªï bi·∫øn)\n",
    "STOPWORDS = set([\n",
    "    \"th√¨\", \"l√†\", \"m√†\", \"c·ªßa\", \"nh·ªØng\", \"c√°c\", \"ƒë·ªÉ\", \"v√†\", \"v·ªõi\", \"c√≥\", \n",
    "    \"trong\", \"ƒë√£\", \"ƒëang\", \"s·∫Ω\", \"ƒë∆∞·ª£c\", \"b·ªã\", \"t·∫°i\", \"v√¨\", \"nh∆∞\", \"n√†y\",\n",
    "    \"cho\", \"v·ªÅ\", \"m·ªôt\", \"ng∆∞·ªùi\", \"khi\", \"ra\", \"v√†o\", \"l√™n\", \"xu·ªëng\",\n",
    "    \"t√¥i\", \"ch√∫ng_t√¥i\", \"b·∫°n\", \"h·ªç\", \"ch√∫ng_ta\", \"theo\", \"√¥ng\", \"b√†\",\n",
    "    \"nhi·ªÅu\", \"√≠t\", \"r·∫•t\", \"qu√°\", \"l·∫Øm\", \"nh∆∞ng\", \"tuy_nhi√™n\", \"n·∫øu\", \"d√π\",\n",
    "    \"b√†i\", \"vi·∫øt\", \"·∫£nh\", \"video\", \"clip\", \"ngu·ªìn\" # T·ª´ r√°c hay g·∫∑p trong b√°o\n",
    "])\n",
    "\n",
    "def normalize_text(text):\n",
    "    return unicodedata.normalize('NFC', text)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 1. Chu·∫©n h√≥a Unicode\n",
    "    text = normalize_text(text)\n",
    "    # 2. T√°ch t·ª´ (H√† N·ªôi -> H√†_N·ªôi)\n",
    "    tokenized = ViTokenizer.tokenize(text)\n",
    "    # 3. X√≥a Stopwords & Chuy·ªÉn th∆∞·ªùng\n",
    "    words = tokenized.split()\n",
    "    clean_words = [w for w in words if w.lower() not in STOPWORDS]\n",
    "    return \" \".join(clean_words)\n",
    "\n",
    "print(\"‚è≥ ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...\")\n",
    "\n",
    "# ƒê·ªçc file hi·ªán t·∫°i\n",
    "if JSONL_PATH.exists():\n",
    "    df = pd.read_json(JSONL_PATH, lines=True)\n",
    "    print(f\"‚úÖ ƒê√£ ƒë·ªçc {len(df)} d√≤ng d·ªØ li·ªáu g·ªëc.\")\n",
    "    \n",
    "    # --- QUAN TR·ªåNG: T·∫†O C·ªòT D·ªÆ LI·ªÜU CHU·∫®N ---\n",
    "    # 1. T·∫°o c·ªôt 'raw_text' (Gi·ªØ nguy√™n vƒÉn b·∫£n g·ªëc, ch·ªâ chu·∫©n h√≥a Unicode nh·∫π)\n",
    "    # N·∫øu ch∆∞a c√≥ raw_text th√¨ l·∫•y t·ª´ text hi·ªán t·∫°i (v√¨ text hi·ªán t·∫°i c·ªßa b·∫°n ƒëang l√† raw)\n",
    "    if 'raw_text' not in df.columns:\n",
    "        print(\"üîß ƒêang t·∫°o c·ªôt 'raw_text' t·ª´ d·ªØ li·ªáu g·ªëc...\")\n",
    "        df['raw_text'] = df['text'].apply(normalize_text)\n",
    "    \n",
    "    # 2. X·ª≠ l√Ω l·∫°i c·ªôt 'text' (Tokenize + Remove Stopwords) cho TF-IDF/LSTM\n",
    "    print(\"üîß ƒêang t√°ch t·ª´ v√† x√≥a stopwords cho c·ªôt 'text' (M·∫•t kho·∫£ng 1-2 ph√∫t)...\")\n",
    "    # D√πng tqdm ƒë·ªÉ hi·ªán ti·∫øn ƒë·ªô n·∫øu th√≠ch, nh∆∞ng apply c≈©ng nhanh\n",
    "    tqdm.pandas(desc=\"Processing Text\")\n",
    "    df['text'] = df['raw_text'].progress_apply(preprocess_text)\n",
    "    \n",
    "    # 3. ƒê·∫£m b·∫£o c·ªôt label_name\n",
    "    target_col = 'label_name'\n",
    "    if target_col not in df.columns and 'label' in df.columns:\n",
    "        df['label_name'] = df['label']\n",
    "\n",
    "    # L∆∞u ƒë√® l·∫°i file ƒë√£ x·ª≠ l√Ω s·∫°ch s·∫Ω (l·∫ßn sau ch·∫°y s·∫Ω nhanh h∆°n)\n",
    "    df.to_json(JSONL_PATH, orient=\"records\", lines=True)\n",
    "    print(\"üíæ ƒê√£ l∆∞u file d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω xong.\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y file nlp_dataset.jsonl\")\n",
    "    # N·∫øu m·∫•t file th√¨ ph·∫£i ch·∫°y l·∫°i code qu√©t folder txt (nh∆∞ c√°c b∆∞·ªõc tr∆∞·ªõc)\n",
    "\n",
    "# --- KI·ªÇM TRA K·∫æT QU·∫¢ ---\n",
    "print(f\"\\nüëÄ M·∫´u d·ªØ li·ªáu sau khi x·ª≠ l√Ω:\")\n",
    "print(f\"‚ñ∂Ô∏è RAW (Cho PhoBERT): {df['raw_text'].iloc[0][:100]}...\")\n",
    "print(f\"‚ñ∂Ô∏è CLEAN (Cho LSTM/SVM): {df['text'].iloc[0][:100]}...\")\n",
    "\n",
    "# Encode nh√£n & Chia t·∫≠p\n",
    "le = LabelEncoder()\n",
    "df['label_id'] = le.fit_transform(df[target_col])\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[target_col])\n",
    "print(f\"\\nüìä Train: {len(train_df)} | Test: {len(test_df)}\")\n",
    "print(f\"üìã S·ªë l∆∞·ª£ng nh√£n: {num_classes}\")\n",
    "\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46482c1e",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è 1. Machine Learning (TF-IDF + NB + SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d88215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ ƒêang t·∫°o TF-IDF Vector...\n",
      "‚úÖ K√≠ch th∆∞·ªõc ma tr·∫≠n Train: (92150, 30000)\n",
      "ü§ñ Training Naive Bayes...\n",
      "   -> Accuracy: 0.8184\n",
      "‚öîÔ∏è Training SVM (LinearSVC)...\n",
      "   -> Accuracy: 0.8920\n"
     ]
    }
   ],
   "source": [
    "print(\"‚è≥ ƒêang t·∫°o TF-IDF Vector...\")\n",
    "tfidf = TfidfVectorizer(max_features=30000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf.fit_transform(train_df['text'])\n",
    "X_test_tfidf = tfidf.transform(test_df['text'])\n",
    "print(f\"‚úÖ K√≠ch th∆∞·ªõc ma tr·∫≠n Train: {X_train_tfidf.shape}\")\n",
    "\n",
    "results = []\n",
    "\n",
    "# --- Naive Bayes ---\n",
    "print(\"ü§ñ Training Naive Bayes...\")\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tfidf, train_df['label_id'])\n",
    "acc_nb = accuracy_score(test_df['label_id'], nb.predict(X_test_tfidf))\n",
    "results.append({\"Model\": \"Naive Bayes\", \"Accuracy\": acc_nb})\n",
    "print(f\"   -> Accuracy: {acc_nb:.4f}\")\n",
    "\n",
    "# --- SVM ---\n",
    "print(\"‚öîÔ∏è Training SVM (LinearSVC)...\")\n",
    "svm = LinearSVC(dual=False)\n",
    "svm.fit(X_train_tfidf, train_df['label_id'])\n",
    "acc_svm = accuracy_score(test_df['label_id'], svm.predict(X_test_tfidf))\n",
    "results.append({\"Model\": \"SVM\", \"Accuracy\": acc_svm})\n",
    "print(f\"   -> Accuracy: {acc_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f44235c",
   "metadata": {},
   "source": [
    "## üß† 2. Deep Learning (LSTM - PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86bd658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Chu·∫©n b·ªã d·ªØ li·ªáu cho LSTM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\trading\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1371: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:39.)\n",
      "  return t.to(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ B·∫Øt ƒë·∫ßu Train LSTM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1440/1440 [00:04<00:00, 317.78it/s]\n",
      "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1440/1440 [00:04<00:00, 340.70it/s]\n",
      "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1440/1440 [00:04<00:00, 346.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LSTM Accuracy: 0.7829\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"‚è≥ Chu·∫©n b·ªã d·ªØ li·ªáu cho LSTM...\")\n",
    "\n",
    "# 1. X√¢y b·ªô t·ª´ ƒëi·ªÉn (Vocab)\n",
    "counter = Counter()\n",
    "for text in train_df['text']: counter.update(text.split())\n",
    "vocab = {word: i+2 for i, (word, _) in enumerate(counter.most_common(20000))}\n",
    "vocab['<PAD>'] = 0; vocab['<UNK>'] = 1\n",
    "MAX_LEN = 500\n",
    "\n",
    "# 2. H√†m convert text -> sequence\n",
    "def text_to_seq(text, vocab, max_len):\n",
    "    seq = [vocab.get(word, 1) for word in text.split()]\n",
    "    if len(seq) < max_len: seq += [0] * (max_len - len(seq))\n",
    "    else: seq = seq[:max_len]\n",
    "    return seq\n",
    "\n",
    "# 3. Dataset Class\n",
    "class LSTMDataset(Dataset):\n",
    "    def __init__(self, df, vocab):\n",
    "        self.x = [text_to_seq(t, vocab, MAX_LEN) for t in df['text']]\n",
    "        self.y = df['label_id'].values\n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.x[idx], dtype=torch.long), torch.tensor(self.y[idx], dtype=torch.long)\n",
    "\n",
    "train_loader_lstm = DataLoader(LSTMDataset(train_df, vocab), batch_size=64, shuffle=True)\n",
    "test_loader_lstm = DataLoader(LSTMDataset(test_df, vocab), batch_size=64)\n",
    "\n",
    "# 4. Model Class (FIXED DROPOUT WARNING)\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, n_classes):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        # FIX: B·ªè dropout=0.2 ƒëi v√¨ num_layers=1\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, dropout=0.0)\n",
    "        self.fc = nn.Linear(hidden_dim, n_classes)\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        _, (hn, _) = self.lstm(x)\n",
    "        return self.fc(hn[-1])\n",
    "\n",
    "model_lstm = LSTMClassifier(len(vocab)+2, 100, 100, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model_lstm.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"üöÄ B·∫Øt ƒë·∫ßu Train LSTM...\")\n",
    "for epoch in range(10):\n",
    "    model_lstm.train()\n",
    "    # D√πng tqdm b·∫£n chu·∫©n\n",
    "    for x, y in tqdm(train_loader_lstm, desc=f\"Epoch {epoch+1}\"):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model_lstm(x), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Eval\n",
    "model_lstm.eval()\n",
    "preds, targets = [], []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader_lstm:\n",
    "        preds.extend(torch.argmax(model_lstm(x.to(device)), dim=1).cpu().numpy())\n",
    "        targets.extend(y.numpy())\n",
    "acc_lstm = accuracy_score(targets, preds)\n",
    "results.append({\"Model\": \"LSTM\", \"Accuracy\": acc_lstm})\n",
    "print(f\"‚úÖ LSTM Accuracy: {acc_lstm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f13d56e",
   "metadata": {},
   "source": [
    "## üî• 3. PhoBERT (Transformers - PyTorch)\n",
    "*L∆∞u √Ω: N·∫øu ch·∫°y tr√™n CPU, h√£y gi·∫£m s·ªë l∆∞·ª£ng d·ªØ li·ªáu train n·∫øu th·∫•y m√°y b·ªã ch·∫≠m.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a175e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ ƒêang load PhoBERT...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3df9e48a73244868699bb5f2335bc84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/557 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\trading\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ASUS\\.cache\\huggingface\\hub\\models--vinai--phobert-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad1c2278913451c841ebcb6a8505d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01a8e01a2fb48a188ec14d3c48af81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bpe.codes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdda98d2427419b8818fb9aa9e83e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ch·∫°y GPU: D√πng 5000 m·∫´u train (c√≥ th·ªÉ tƒÉng n·∫øu GPU m·∫°nh).\n",
      "‚ùå L·ªói khi ch·∫°y PhoBERT: 'raw_text'\n"
     ]
    }
   ],
   "source": [
    "print(\"‚è≥ ƒêang load PhoBERT...\")\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "    \n",
    "    class PhoBERTDataset(Dataset):\n",
    "        def __init__(self, df, tokenizer, max_len=256):\n",
    "            self.texts = df['raw_text'].tolist()\n",
    "            self.labels = df['label_id'].tolist()\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_len = max_len\n",
    "        def __len__(self): return len(self.labels)\n",
    "        def __getitem__(self, idx):\n",
    "            enc = self.tokenizer(str(self.texts[idx]), truncation=True, padding='max_length', max_length=self.max_len, return_tensors='pt')\n",
    "            return {\n",
    "                'input_ids': enc['input_ids'].squeeze(),\n",
    "                'attention_mask': enc['attention_mask'].squeeze(),\n",
    "                'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "            }\n",
    "\n",
    "    # T√πy ch·ªânh d·ªØ li·ªáu cho CPU/GPU\n",
    "    if device.type == 'cpu':\n",
    "        print(\"‚ö†Ô∏è Ch·∫°y CPU: Gi·∫£m d·ªØ li·ªáu train xu·ªëng 200 m·∫´u ƒë·ªÉ demo (Tr√°nh treo m√°y).\")\n",
    "        train_sub = train_df[:200]\n",
    "        test_sub = test_df[:50]\n",
    "        batch_size = 4\n",
    "    else:\n",
    "        print(\"‚úÖ Ch·∫°y GPU: D√πng 5000 m·∫´u train (c√≥ th·ªÉ tƒÉng n·∫øu GPU m·∫°nh).\")\n",
    "        train_sub = train_df\n",
    "        test_sub = test_df\n",
    "        batch_size = 8\n",
    "\n",
    "    train_loader_bert = DataLoader(PhoBERTDataset(train_sub, tokenizer), batch_size=batch_size, shuffle=True)\n",
    "    test_loader_bert = DataLoader(PhoBERTDataset(test_sub, tokenizer), batch_size=batch_size)\n",
    "\n",
    "    model_bert = AutoModelForSequenceClassification.from_pretrained(\"vinai/phobert-base\", num_labels=num_classes)\n",
    "    model_bert.to(device)\n",
    "    optimizer = AdamW(model_bert.parameters(), lr=2e-5)\n",
    "\n",
    "    print(\"üöÄ B·∫Øt ƒë·∫ßu Fine-tune PhoBERT...\")\n",
    "    for epoch in range(2):\n",
    "        model_bert.train()\n",
    "        loop = tqdm(train_loader_bert, desc=f\"Epoch {epoch+1}\")\n",
    "        for batch in loop:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model_bert(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            outputs.loss.backward()\n",
    "            optimizer.step()\n",
    "            loop.set_postfix(loss=outputs.loss.item())\n",
    "\n",
    "    # Eval\n",
    "    model_bert.eval()\n",
    "    preds_bert, targets_bert = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader_bert, desc=\"Evaluating\"):\n",
    "            outputs = model_bert(batch['input_ids'].to(device), attention_mask=batch['attention_mask'].to(device))\n",
    "            preds_bert.extend(torch.argmax(outputs.logits, dim=1).cpu().numpy())\n",
    "            targets_bert.extend(batch['labels'].numpy())\n",
    "            \n",
    "    acc_bert = accuracy_score(targets_bert, preds_bert)\n",
    "    results.append({\"Model\": \"PhoBERT\", \"Accuracy\": acc_bert})\n",
    "    print(f\"‚úÖ PhoBERT Accuracy: {acc_bert:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªói khi ch·∫°y PhoBERT: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b359db0",
   "metadata": {},
   "source": [
    "## üèÜ 4. T·ªïng k·∫øt & Xu·∫•t b√°o c√°o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3464976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ B·∫¢NG X·∫æP H·∫†NG CU·ªêI C√ôNG:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Accuracy",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ee138085-4d4f-4356-9bf9-9856225dad1e",
       "rows": [
        [
         "1",
         "SVM",
         "0.8919611077350464"
        ],
        [
         "0",
         "Naive Bayes",
         "0.8184304193072315"
        ],
        [
         "2",
         "LSTM",
         "0.7829238649188298"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.891961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.818430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.782924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Accuracy\n",
       "1          SVM  0.891961\n",
       "0  Naive Bayes  0.818430\n",
       "2         LSTM  0.782924"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ ƒê√£ l∆∞u file Excel t·∫°i: c:\\Users\\ASUS\\Programming-Coding\\Python\\NLM\\NLP_TC_Group4\\reports\\final_benchmark_local.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_28000\\1681316293.py:12: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=\"Accuracy\", y=\"Model\", data=results_df, palette=\"viridis\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).sort_values(by=\"Accuracy\", ascending=False)\n",
    "print(\"\\nüèÜ B·∫¢NG X·∫æP H·∫†NG CU·ªêI C√ôNG:\")\n",
    "display(results_df)\n",
    "\n",
    "# L∆∞u Excel v√†o folder reports\n",
    "save_path = REPORT_DIR / \"final_benchmark_local.xlsx\"\n",
    "results_df.to_excel(save_path, index=False)\n",
    "print(f\"\\nüíæ ƒê√£ l∆∞u file Excel t·∫°i: {save_path}\")\n",
    "\n",
    "# V·∫Ω bi·ªÉu ƒë·ªì\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Accuracy\", y=\"Model\", data=results_df, palette=\"viridis\")\n",
    "plt.title(f\"Model Comparison (Device: {device})\")\n",
    "plt.xlim(0.0, 1.0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORT_DIR / \"chart_benchmark_local.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
