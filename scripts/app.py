import streamlit as st
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import joblib
import unicodedata
import requests
import io
from bs4 import BeautifulSoup
from pyvi import ViTokenizer
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter

# --- Cáº¤U HÃŒNH TRANG ---
st.set_page_config(
    page_title="Personal Content Analyzer (TextCNN)",
    page_icon="ðŸ§ ",
    layout="wide"
)

# --- Cáº¤U HÃŒNH ÄÆ¯á»œNG DáºªN (Cháº¡y trong folder scripts) ---
CURRENT_DIR = Path(__file__).parent 
BASE_DIR = CURRENT_DIR.parent 
MODEL_DIR = BASE_DIR / "models"
if not MODEL_DIR.exists(): MODEL_DIR = CURRENT_DIR / "models" # Fallback

# --- 1. KHá»žI Táº O SESSION STATE ---
if 'history' not in st.session_state:
    st.session_state['history'] = []

# --- 2. Äá»ŠNH NGHÄ¨A MODEL TEXT-CNN (MODEL CHÃNH) ---
class TextCNN(nn.Module):
    def __init__(self, vocab_size, embed_dim, num_classes, filter_sizes=[2, 3, 4], num_filters=100):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        # Táº¡o 3 lá»›p Conv song song quÃ©t cÃ¡c cá»­a sá»• 2 tá»«, 3 tá»«, 4 tá»«
        self.convs = nn.ModuleList([
            nn.Conv2d(1, num_filters, (k, embed_dim)) for k in filter_sizes
        ])
        self.fc = nn.Linear(len(filter_sizes) * num_filters, num_classes)
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        # x: [Batch, Seq_Len]
        x = self.embedding(x)             # [Batch, Seq_Len, Embed]
        x = x.unsqueeze(1)                # [Batch, 1, Seq_Len, Embed] -> ThÃªm channel dimension
        
        # Qua Conv + ReLU + MaxPool
        # Káº¿t quáº£ lÃ  danh sÃ¡ch cÃ¡c tensor Ä‘Ã£ Ä‘Æ°á»£c pool
        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs] 
        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  
        
        # Ná»‘i láº¡i vÃ  qua lá»›p Fully Connected
        x = torch.cat(x, 1)
        x = self.dropout(x)
        logits = self.fc(x)
        return logits

# --- 3. CÃC HÃ€M Xá»¬ LÃ Dá»® LIá»†U ---
STOPWORDS = {
    "thÃ¬", "lÃ ", "mÃ ", "cá»§a", "nhá»¯ng", "cÃ¡c", "Ä‘á»ƒ", "vÃ ", "vá»›i", "cÃ³", 
    "trong", "Ä‘Ã£", "Ä‘ang", "sáº½", "Ä‘Æ°á»£c", "bá»‹", "táº¡i", "vÃ¬", "nhÆ°", "nÃ y",
    "cho", "vá»", "má»™t", "ngÆ°á»i", "khi", "ra", "vÃ o", "lÃªn", "xuá»‘ng",
    "tÃ´i", "chÃºng_tÃ´i", "báº¡n", "há»", "chÃºng_ta", "theo", "Ã´ng", "bÃ ",
    "nhiá»u", "Ã­t", "ráº¥t", "quÃ¡", "láº¯m", "nhÆ°ng", "tuy_nhiÃªn", "náº¿u", "dÃ¹",
    "bÃ i", "viáº¿t", "áº£nh", "video", "clip", "nguá»“n", "theo", "vnexpress", "dÃ¢n trÃ­"
}

def normalize_text(text): return unicodedata.normalize('NFC', text)

def preprocess_text(text):
    text = normalize_text(text)
    tokenized = ViTokenizer.tokenize(text)
    words = tokenized.split()
    clean_words = [w for w in words if w.lower() not in STOPWORDS and len(w) > 1]
    return " ".join(clean_words)

def text_to_sequence(text, vocab, max_len=1024):
    # Chuyá»ƒn text thÃ nh chuá»—i sá»‘ ID dá»±a trÃªn vocab
    seq = [vocab.get(w, 1) for w in text.split()] # 1 is <UNK>
    # Padding hoáº·c Cáº¯t
    if len(seq) < max_len:
        seq += [0] * (max_len - len(seq)) # 0 is <PAD>
    else:
        seq = seq[:max_len]
    return seq

def crawl_news_from_url(url):
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/91.0.4472.124 Safari/537.36'}
    try:
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.content, 'html.parser')
        
        title = soup.title.string if soup.title else "Link khÃ´ng tiÃªu Ä‘á»"
        
        # Láº¥y ná»™i dung thÃ´ng minh
        paragraphs = soup.find_all('p', class_=['Normal', 'description', 'content', 'detail-content'])
        if not paragraphs: paragraphs = soup.find_all('p') 
        
        content = "\n".join([p.text.strip() for p in paragraphs if len(p.text.strip()) > 50])
        
        if len(content) < 100: return None, None, "Ná»™i dung quÃ¡ ngáº¯n (cÃ³ thá»ƒ bá»‹ cháº·n hoáº·c web dÃ¹ng JS)."
        return title, content, None
    except Exception as e: return None, None, str(e)

# --- 4. LOAD MODELS (CACHE) ---
@st.cache_resource
def load_resources():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    try:
        # 1. Load Label Encoder
        le = joblib.load(MODEL_DIR / "label_encoder.pkl")
        
        # 2. Load TextCNN Model
        # LÆ°u Ã½: TÃªn file pháº£i khá»›p vá»›i lÃºc báº¡n save trong model.ipynb (vÃ­ dá»¥: textcnn_model.pth)
        # Náº¿u báº¡n save tÃªn khÃ¡c, hÃ£y sá»­a láº¡i dÃ²ng nÃ y
        checkpoint_path = MODEL_DIR / "textcnn_model.pth" 
        
        if not checkpoint_path.exists():
            st.error(f"KhÃ´ng tÃ¬m tháº¥y file: {checkpoint_path}")
            return None, None, None, None
            
        checkpoint = torch.load(checkpoint_path, map_location=device)
        vocab = checkpoint['vocab']
        config = checkpoint['config']
        
        model = TextCNN(
            vocab_size=config['vocab_size'], 
            embed_dim=config['embed_dim'], 
            num_classes=config['num_classes'],
            filter_sizes=config.get('filter_sizes', [2,3,4]),
            num_filters=config.get('num_filters', 100)
        )
        model.load_state_dict(checkpoint['model_state'])
        model.to(device)
        model.eval()
        
        return le, model, vocab, config
        
    except Exception as e:
        st.error(f"Lá»—i load model: {e}")
        return None, None, None, None

le, cnn_model, vocab, cnn_config = load_resources()
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# --- 5. GIAO DIá»†N CHÃNH ---
with st.sidebar:
    st.title("âš™ï¸ Äiá»u khiá»ƒn")
    if st.button("ðŸ—‘ï¸ XÃ³a dá»¯ liá»‡u", type="primary"):
        st.session_state['history'] = []
        st.rerun()
    st.info(f"Model: **TextCNN**\nDevice: {device}")
    st.caption("TextCNN vÆ°á»£t trá»™i nhá» kháº£ nÄƒng báº¯t cÃ¡c cá»¥m tá»« cá»¥c bá»™ (n-grams) quan trá»ng.")

st.title("ðŸš€ Smart Content Analytics")
st.markdown("Há»‡ thá»‘ng phÃ¢n tÃ­ch xu hÆ°á»›ng Ä‘á»c sá»­ dá»¥ng **TextCNN Deep Learning**.")

if not cnn_model:
    st.warning("âš ï¸ Äang cháº¡y á»Ÿ cháº¿ Ä‘á»™ Demo giao diá»‡n (ChÆ°a load Ä‘Æ°á»£c Model).")
    st.stop()

# --- INPUT AREA ---
with st.container(border=True):
    st.subheader("ðŸ“¥ Nháº­p ná»™i dung phÃ¢n tÃ­ch")
    
    tab1, tab2, tab3 = st.tabs(["ðŸ”— Link BÃ¡o", "ðŸ“ VÄƒn báº£n", "ðŸ“‚ File Text"])
    
    input_payload = None
    input_source = ""
    
    with tab1:
        url = st.text_input("URL bÃ i bÃ¡o:", placeholder="https://vnexpress.net/...")
        if st.button("PhÃ¢n tÃ­ch Link"):
            if url:
                with st.spinner("Äang cÃ o dá»¯ liá»‡u..."):
                    t, c, e = crawl_news_from_url(url)
                    if e: st.error(e)
                    else:
                        input_payload = c
                        input_source = t
    
    with tab2:
        txt = st.text_area("Ná»™i dung:", height=100)
        if st.button("PhÃ¢n tÃ­ch Text"):
            if txt:
                input_payload = txt
                input_source = f"VÄƒn báº£n ({txt[:20]}...)"
                
    with tab3:
        f = st.file_uploader("Chá»n file .txt", type="txt")
        if f and st.button("PhÃ¢n tÃ­ch File"):
            stringio = io.StringIO(f.getvalue().decode("utf-8"))
            input_payload = stringio.read()
            input_source = f.name

    # --- CORE PREDICTION LOGIC ---
    if input_payload:
        # 1. Preprocess
        clean_text = preprocess_text(input_payload)
        
        # 2. Vectorize (Sequence)
        max_len = cnn_config.get('max_len', 1024)
        seq = text_to_sequence(clean_text, vocab, max_len)
        tensor_in = torch.tensor([seq], dtype=torch.long).to(device)
        
        # 3. Predict with TextCNN
        with torch.no_grad():
            logits = cnn_model(tensor_in)
            probs = torch.softmax(logits, dim=1)
            conf, idx = torch.max(probs, dim=1)
            
            label = le.inverse_transform([idx.item()])[0]
            confidence = conf.item()
            
        # 4. Save to History
        st.session_state['history'].append({
            "source": input_source,
            "topic": label,
            "conf": confidence,
            "timestamp": pd.Timestamp.now()
        })
        
        st.success(f"Káº¿t quáº£: **{label}** ({confidence:.1%})")

# --- DASHBOARD AREA ---
st.divider()

if st.session_state['history']:
    st.subheader("ðŸ“Š Dashboard Xu hÆ°á»›ng cá»§a báº¡n")
    
    df = pd.DataFrame(st.session_state['history'])
    
    # KPIs
    k1, k2, k3 = st.columns(3)
    k1.metric("Tá»•ng bÃ i Ä‘Ã£ Ä‘á»c", len(df))
    k2.metric("Chá»§ Ä‘á» Top 1", df['topic'].mode()[0])
    k3.metric("Äá»™ tin cáº­y AI", f"{df['conf'].mean():.1%}")
    
    # Charts
    c1, c2 = st.columns([1, 1])
    
    with c1:
        st.caption("PhÃ¢n bá»‘ chá»§ Ä‘á»")
        counts = df['topic'].value_counts()
        fig, ax = plt.subplots(figsize=(5,5))
        colors = sns.color_palette('pastel')[0:len(counts)]
        ax.pie(counts, labels=counts.index, autopct='%1.1f%%', colors=colors, startangle=90)
        st.pyplot(fig)
        
    with c2:
        st.caption("Lá»‹ch sá»­ chi tiáº¿t")
        st.dataframe(
            df[['topic', 'source', 'conf']].style.highlight_max(subset=['conf'], color='#d1e7dd'),
            column_config={
                "topic": "Chá»§ Ä‘á»",
                "source": "Nguá»“n",
                "conf": st.column_config.NumberColumn("Äá»™ tin cáº­y", format="%.2f")
            },
            use_container_width=True,
            height=300
        )
else:
    st.info("Dá»¯ liá»‡u phÃ¢n tÃ­ch sáº½ xuáº¥t hiá»‡n á»Ÿ Ä‘Ã¢y sau khi báº¡n nháº­p bÃ i viáº¿t.")