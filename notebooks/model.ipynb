{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiQy1M815eFD"
      },
      "source": [
        "# üöÄ NLP Project: Benchmark 3 Models (SVM - LSTM - PhoBERT)\n",
        "\n",
        "Notebook n√†y ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a cho **Google Colab T4 GPU**.\n",
        "\n",
        "**Quy tr√¨nh:**\n",
        "1.  **Setup**: C√†i ƒë·∫∑t th∆∞ vi·ªán & Mount Google Drive.\n",
        "2.  **Data**: Load d·ªØ li·ªáu t·ª´ folder `final` tr√™n Drive.\n",
        "3.  **Train & Eval**:\n",
        "    * ü§ñ **SVM**: Machine Learning c∆° b·∫£n (Baseline).\n",
        "    * üß† **LSTM**: Deep Learning (PyTorch).\n",
        "    * üî• **PhoBERT**: Transformer (State-of-the-Art).\n",
        "4.  **Report**: Xu·∫•t k·∫øt qu·∫£ ra file Excel v√† bi·ªÉu ƒë·ªì."
      ],
      "id": "IiQy1M815eFD"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwhdsN5H5eFF",
        "outputId": "13177814-e128-4e67-ae35-c0935f78c453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n",
            "\n",
            "‚úÖ ƒêang ch·∫°y tr√™n thi·∫øt b·ªã: cuda\n",
            "   ‚û§ GPU Name: Tesla T4\n",
            "   ‚û§ Memory: 15.83 GB\n"
          ]
        }
      ],
      "source": [
        "# --- 1. SETUP & CONFIG ---\n",
        "!pip install -q pyvi transformers torch scikit-learn openpyxl matplotlib seaborn\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "from pyvi import ViTokenizer\n",
        "import gc\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ki·ªÉm tra GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"\\n‚úÖ ƒêang ch·∫°y tr√™n thi·∫øt b·ªã: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\"   ‚û§ GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   ‚û§ Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"‚ùå C·∫¢NH B√ÅO: Kh√¥ng t√¨m th·∫•y GPU! H√£y v√†o Runtime -> Change runtime type -> T4 GPU.\")"
      ],
      "id": "BwhdsN5H5eFF"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVe2QG7W5eFF",
        "outputId": "c8b41eac-abd5-4df1-d39f-63f4258b687f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ ƒêang chu·∫©n b·ªã d·ªØ li·ªáu...\n",
            "   ƒê·ªçc t·ª´ file cache: /content/drive/MyDrive/final/nlp_dataset.jsonl\n",
            "üìä T·ªïng s·ªë b√†i: 115188\n",
            "üëÄ C√°c c·ªôt hi·ªán c√≥: ['text', 'label_name', 'label_id', 'filename']\n",
            "‚úÖ ƒêang d√πng c·ªôt nh√£n: label_name\n",
            "   Train: 92150 | Test: 23038\n",
            "   S·ªë l∆∞·ª£ng nh√£n: 20\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# --- 2. LOAD DATA ---\n",
        "# üëá S·ª¨A ƒê∆Ø·ªúNG D·∫™N N√ÄY N·∫æU C·∫¶N üëá\n",
        "DRIVE_PATH = Path(\"/content/drive/MyDrive/final\")\n",
        "JSONL_PATH = Path(\"/content/drive/MyDrive/final/nlp_dataset.jsonl\")\n",
        "\n",
        "print(\"‚è≥ ƒêang chu·∫©n b·ªã d·ªØ li·ªáu...\")\n",
        "\n",
        "# N·∫øu ch∆∞a c√≥ file jsonl th√¨ t·∫°o m·ªõi t·ª´ folder raw\n",
        "# 1. ƒê·ªçc file jsonl\n",
        "if JSONL_PATH.exists():\n",
        "    print(f\"   ƒê·ªçc t·ª´ file cache: {JSONL_PATH}\")\n",
        "    df = pd.read_json(JSONL_PATH, lines=True)\n",
        "else:\n",
        "    # N·∫øu ch∆∞a c√≥ th√¨ qu√©t t·ª´ Drive (Backup)\n",
        "    print(\"   Kh√¥ng th·∫•y file cache, ƒëang qu√©t t·ª´ Drive...\")\n",
        "    data = []\n",
        "    if DRIVE_PATH.exists():\n",
        "        for folder in DRIVE_PATH.iterdir():\n",
        "            if folder.is_dir():\n",
        "                topic = folder.name\n",
        "                files = list(folder.glob(\"**/*.txt\"))[:2000] # L·∫•y m·∫´u 2000 b√†i\n",
        "                for file_path in files:\n",
        "                    try:\n",
        "                        with open(file_path, \"r\", encoding=\"utf-16\") as f: content = f.read().strip()\n",
        "                    except:\n",
        "                        try:\n",
        "                            with open(file_path, \"r\", encoding=\"utf-8\") as f: content = f.read().strip()\n",
        "                        except: continue\n",
        "                    if content:\n",
        "                        data.append({\n",
        "                            \"text\": ViTokenizer.tokenize(content),\n",
        "                            \"raw_text\": content,\n",
        "                            \"label_name\": topic, # <--- C·ªôt n√†y l√† label_name\n",
        "                            \"filename\": file_path.name\n",
        "                        })\n",
        "        df = pd.DataFrame(data)\n",
        "        df.to_json(JSONL_PATH, orient=\"records\", lines=True)\n",
        "    else:\n",
        "        print(\"‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y folder data!\")\n",
        "\n",
        "print(f\"üìä T·ªïng s·ªë b√†i: {len(df)}\")\n",
        "print(f\"üëÄ C√°c c·ªôt hi·ªán c√≥: {list(df.columns)}\")\n",
        "\n",
        "# --- QUAN TR·ªåNG: CH·ªåN ƒê√öNG C·ªòT NH√ÉN ---\n",
        "# D·ªØ li·ªáu c·ªßa b·∫°n d√πng 'label_name', n√™n ta tr·ªè th·∫≥ng v√†o n√≥\n",
        "target_col = 'label_name'\n",
        "\n",
        "print(f\"‚úÖ ƒêang d√πng c·ªôt nh√£n: {target_col}\")\n",
        "\n",
        "# M√£ h√≥a nh√£n (Label Encoding)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['label_id'] = le.fit_transform(df[target_col])\n",
        "num_classes = len(le.classes_)\n",
        "\n",
        "# Chia t·∫≠p Train/Test\n",
        "# stratify=df[target_col] gi√∫p chia ƒë·ªÅu t·ªâ l·ªá c√°c nh√£n\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[target_col])\n",
        "\n",
        "print(f\"   Train: {len(train_df)} | Test: {len(test_df)}\")\n",
        "print(f\"   S·ªë l∆∞·ª£ng nh√£n: {num_classes}\")\n",
        "\n",
        "# D·ªçn d·∫πp RAM\n",
        "del df\n",
        "gc.collect()"
      ],
      "id": "wVe2QG7W5eFF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1YJfqzF5eFF"
      },
      "source": [
        "## ü§ñ Model 1: SVM (Machine Learning)"
      ],
      "id": "X1YJfqzF5eFF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4W8oXOD5eFF",
        "outputId": "b7033233-d7c1-4956-9f18-230f3c9147e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ ƒêang hu·∫•n luy·ªán SVM...\n"
          ]
        }
      ],
      "source": [
        "print(\"‚è≥ ƒêang hu·∫•n luy·ªán SVM...\")\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Feature Engineering: TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=20000, ngram_range=(1, 2))\n",
        "X_train_tfidf = tfidf.fit_transform(train_df['text'])\n",
        "X_test_tfidf = tfidf.transform(test_df['text'])\n",
        "\n",
        "# Training\n",
        "svm = LinearSVC(dual=False)\n",
        "svm.fit(X_train_tfidf, train_df['label_id'])\n",
        "\n",
        "# Evaluation\n",
        "y_pred_svm = svm.predict(X_test_tfidf)\n",
        "acc_svm = accuracy_score(test_df['label_id'], y_pred_svm)\n",
        "print(f\"‚úÖ SVM Accuracy: {acc_svm:.4f}\")"
      ],
      "id": "K4W8oXOD5eFF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLhetsuM5eFF"
      },
      "source": [
        "## üß† Model 2: LSTM (PyTorch)"
      ],
      "id": "nLhetsuM5eFF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFuxYDIv5eFG"
      },
      "outputs": [],
      "source": [
        "print(\"‚è≥ ƒêang chu·∫©n b·ªã d·ªØ li·ªáu cho LSTM...\")\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import Counter\n",
        "\n",
        "# 1. X√¢y b·ªô t·ª´ ƒëi·ªÉn (Vocab)\n",
        "def build_vocab(texts, max_features=20000):\n",
        "    counter = Counter()\n",
        "    for text in texts: counter.update(text.split())\n",
        "    vocab = {word: i+2 for i, (word, _) in enumerate(counter.most_common(max_features))}\n",
        "    vocab['<PAD>'] = 0; vocab['<UNK>'] = 1\n",
        "    return vocab\n",
        "\n",
        "vocab = build_vocab(train_df['text'])\n",
        "MAX_LEN = 200\n",
        "\n",
        "# 2. H√†m chuy·ªÉn text sang s·ªë\n",
        "def text_to_seq(text, vocab, max_len):\n",
        "    seq = [vocab.get(word, 1) for word in text.split()]\n",
        "    if len(seq) < max_len: seq += [0] * (max_len - len(seq))\n",
        "    else: seq = seq[:max_len]\n",
        "    return seq\n",
        "\n",
        "# 3. Dataset Class\n",
        "class LSTMDataset(Dataset):\n",
        "    def __init__(self, df, vocab):\n",
        "        self.x = [text_to_seq(t, vocab, MAX_LEN) for t in df['text']]\n",
        "        self.y = df['label_id'].values\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.x[idx], dtype=torch.long), torch.tensor(self.y[idx], dtype=torch.long)\n",
        "\n",
        "train_ds_lstm = LSTMDataset(train_df, vocab)\n",
        "test_ds_lstm = LSTMDataset(test_df, vocab)\n",
        "train_loader_lstm = DataLoader(train_ds_lstm, batch_size=64, shuffle=True)\n",
        "test_loader_lstm = DataLoader(test_ds_lstm, batch_size=64)\n",
        "\n",
        "# 4. Model Architecture\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, n_classes):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, dropout=0.2)\n",
        "        self.fc = nn.Linear(hidden_dim, n_classes)\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        _, (hn, _) = self.lstm(x)\n",
        "        return self.fc(hn[-1])\n",
        "\n",
        "model_lstm = LSTMClassifier(len(vocab)+2, 100, 100, num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model_lstm.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 5. Training Loop\n",
        "print(\"üöÄ B·∫Øt ƒë·∫ßu Train LSTM...\")\n",
        "for epoch in range(5):\n",
        "    model_lstm.train()\n",
        "    for x, y in train_loader_lstm:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model_lstm(x), y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# 6. Evaluate\n",
        "model_lstm.eval()\n",
        "preds, targets = [], []\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader_lstm:\n",
        "        output = model_lstm(x.to(device))\n",
        "        preds.extend(torch.argmax(output, dim=1).cpu().numpy())\n",
        "        targets.extend(y.numpy())\n",
        "acc_lstm = accuracy_score(targets, preds)\n",
        "print(f\"‚úÖ LSTM Accuracy: {acc_lstm:.4f}\")"
      ],
      "id": "qFuxYDIv5eFG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHu01nCq5eFG"
      },
      "source": [
        "## üî• Model 3: PhoBERT (Transformer - PyTorch)"
      ],
      "id": "lHu01nCq5eFG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUdiEvG35eFG"
      },
      "outputs": [],
      "source": [
        "print(\"‚è≥ ƒêang load PhoBERT...\")\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
        "\n",
        "class PhoBERTDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len=128):\n",
        "        self.texts = df['raw_text'].tolist()\n",
        "        self.labels = df['label_id'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "    def __len__(self): return len(self.labels)\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tokenizer(self.texts[idx], truncation=True, padding='max_length', max_length=self.max_len, return_tensors='pt')\n",
        "        return {\n",
        "            'input_ids': enc['input_ids'].squeeze(),\n",
        "            'attention_mask': enc['attention_mask'].squeeze(),\n",
        "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# L·∫•y m·∫´u nh·ªè h∆°n ƒë·ªÉ Train PhoBERT cho nhanh (n·∫øu m√°y y·∫øu c√≥ th·ªÉ gi·∫£m xu·ªëng 5000)\n",
        "train_ds_bert = PhoBERTDataset(train_df[:5000], tokenizer)\n",
        "test_ds_bert = PhoBERTDataset(test_df[:1000], tokenizer)\n",
        "train_loader_bert = DataLoader(train_ds_bert, batch_size=16, shuffle=True)\n",
        "test_loader_bert = DataLoader(test_ds_bert, batch_size=16)\n",
        "\n",
        "model_bert = AutoModelForSequenceClassification.from_pretrained(\"vinai/phobert-base\", num_labels=num_classes)\n",
        "model_bert.to(device)\n",
        "optimizer = AdamW(model_bert.parameters(), lr=2e-5)\n",
        "\n",
        "print(\"üöÄ B·∫Øt ƒë·∫ßu Fine-tune PhoBERT (Kho·∫£ng 5-10 ph√∫t)...\")\n",
        "for epoch in range(2):\n",
        "    model_bert.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader_bert:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_bert(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"   Epoch {epoch+1} Loss: {total_loss/len(train_loader_bert):.4f}\")\n",
        "\n",
        "# Evaluate\n",
        "model_bert.eval()\n",
        "preds_bert, targets_bert = [], []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader_bert:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        outputs = model_bert(input_ids, attention_mask=attention_mask)\n",
        "        preds_bert.extend(torch.argmax(outputs.logits, dim=1).cpu().numpy())\n",
        "        targets_bert.extend(batch['labels'].numpy())\n",
        "\n",
        "acc_bert = accuracy_score(targets_bert, preds_bert)\n",
        "print(f\"‚úÖ PhoBERT Accuracy: {acc_bert:.4f}\")"
      ],
      "id": "uUdiEvG35eFG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZT3hvBpn5eFG"
      },
      "outputs": [],
      "source": [
        "# --- 4. T·ªîNG K·∫æT & XU·∫§T B√ÅO C√ÅO ---\n",
        "results_df = pd.DataFrame([\n",
        "    {\"Model\": \"SVM (Baseline)\", \"Accuracy\": acc_svm},\n",
        "    {\"Model\": \"LSTM (PyTorch)\", \"Accuracy\": acc_lstm},\n",
        "    {\"Model\": \"PhoBERT (Transformer)\", \"Accuracy\": acc_bert}\n",
        "]).sort_values(by=\"Accuracy\", ascending=False)\n",
        "\n",
        "print(\"\\nüèÜ B·∫¢NG X·∫æP H·∫†NG:\")\n",
        "display(results_df)\n",
        "\n",
        "# L∆∞u v√†o Drive\n",
        "REPORT_DIR = DRIVE_PATH.parent / \"reports\"\n",
        "REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "save_path = REPORT_DIR / \"final_benchmark_t4.xlsx\"\n",
        "results_df.to_excel(save_path, index=False)\n",
        "print(f\"\\nüíæ ƒê√£ l∆∞u file Excel t·∫°i: {save_path}\")\n",
        "\n",
        "# V·∫Ω bi·ªÉu ƒë·ªì\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=\"Accuracy\", y=\"Model\", data=results_df, palette=\"viridis\")\n",
        "plt.xlim(0.0, 1.0)\n",
        "plt.title(\"So s√°nh ƒë·ªô ch√≠nh x√°c tr√™n T4 GPU\")\n",
        "plt.savefig(REPORT_DIR / \"chart_benchmark.png\")\n",
        "plt.show()"
      ],
      "id": "ZT3hvBpn5eFG"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}