Những chú gấu bông vốn là “bạn thân” trong trí tưởng tượng trẻ nhỏ ngày nay đã biết trò chuyện nhờ chatbot AI tích hợp sẵn. Thị trường đồ chơi bước vào kỷ nguyên mới, nhưng cũng đồng thời phơi bày những rủi ro nghiêm trọng.

Chatbot vốn đã có rủi ro với người lớn, từ việc kích hoạt ảo giác đến đưa ra thông tin sai lệch. GPT-4o của OpenAI hiện là mô hình được nhiều hãng đồ chơi sử dụng nhưng việc dùng LLM trong sản phẩm cho trẻ đang mở ra loạt câu hỏi về mức độ bảo vệ mà nhà sản xuất cần áp dụng.

Trong khi đó, thị trường đồ chơi AI tại Trung Quốc đang bùng nổ với hơn 1.500 công ty và nhiều sản phẩm đã tràn sang Mỹ. Mattel, hãng làm ra búp bê Barbie, cũng vừa công bố hợp tác với OpenAI.

Đồ chơi AI và nguy cơ "lệch chuẩn"

Khác Teddy những năm 1980, đồ chơi AI ngày nay kết nối Wi-Fi, thu âm câu hỏi bằng micro và sử dụng LLM để tạo câu trả lời theo thời gian thực.

Những sản phẩm như Grok plushie của Curio, robot Miko, gấu chuyện Poe hay robot thú cưng Loona đều trò chuyện được, đưa trẻ vào giao tiếp tương tác liên tục.

Song, nó không phải không có rủi ro. Một ví dụ gây sốc đến từ gấu Kumma của FoloToy (Singapore), sử dụng GPT-4o và được bán với giá 99 USD.

Theo báo cáo của PIRG (Mỹ), gấu Kumma đã “chỉ chỗ tìm vật nguy hiểm” và thậm chí tham gia hội thoại “mang nội dung tình dục”.

OpenAI sau đó đình chỉ FoloToy vì vi phạm chính sách cấm “khai thác, gây nguy hại hoặc tình dục hóa bất kỳ ai dưới 18 tuổi”.

CEO Larry Wang nói với CNN rằng công ty đã thu hồi sản phẩm và tiến hành kiểm tra nội bộ. Nhưng chỉ vài ngày sau, FoloToy thông báo trên X sản phẩm được “tái giới thiệu sau khi rà soát và tăng cường mô-đun an toàn”.

FoloToy phải tạm thời thu hồi gấu bông Kumma tích hợp AI và các sản phẩm khác do lo ngại về các cuộc trò chuyện độc hại với trẻ nhỏ. Ảnh: Folotoy

Theo Giáo sư Subodha Kumar từ đại học Temple University, hầu hết đồ chơi AI không dùng riêng một LLM mà kết hợp để giảm rủi ro. Tuy vậy, chúng vẫn có thể gợi ý vị trí các vật dụng nguy hiểm nếu bị hỏi “quá mức”, theo PIRG.

Chuyên gia đồ chơi Chris Byrne gọi các phản hồi lệch lạc này là “kịch bản ngày tận thế” của đồ chơi AI, dù không phải sản phẩm nào cũng sẽ gây ra sự cố.

Đồ chơi AI có đang được đặt “hàng rào an toàn”?

PIRG nhận định nhiều đồ chơi AI chưa sẵn sàng sử dụng rộng rãi vì dễ gây nghiện, phản hồi thiếu ổn định và thiên về bạn đồng hành xã hội hơn là giáo dục.

Tuy vậy, một số sản phẩm đã có cơ chế chuyển hướng khi trẻ đặt câu hỏi nhạy cảm, hay điều chỉnh nội dung theo độ tuổi.

Robot Miko 3 có ứng dụng đi kèm để cha mẹ khóa thiết bị hoặc xem bản ghi hội thoại theo thời gian thực. Grok plushie cũng có tính năng giám sát trong app, cho phép phụ huynh thiết lập giới hạn hành vi.

“Ý tưởng hay nhất là cha mẹ có thể tự đặt các hàng rào bảo vệ, kiểm soát nội dung và hành vi của đồ chơi”, chuyên gia R.J. Cross từ PIRG nói.

Ngoài ra, còn có nỗi lo về quyền riêng tư. Năm 2015, đồ chơi Hello Barbie gây tranh cãi vì có mic, kết nối Wi-Fi và ghi nhớ các cuộc trò chuyện.

Giờ đây, đồ chơi AI cũng có thể lưu dữ liệu nhạy cảm như tên, gương mặt, giọng nói hay vị trí của trẻ. “Đồ chơi AI giống ‘sói đội lốt cừu’, vì rất khó biết bạn đang mất bao nhiêu quyền riêng tư”, nhà sáng lập Azhelle Wade của hãng tư vấn Toy Coach cảnh báo.

Giáo sư Kumar nhấn mạnh dữ liệu trẻ em có thể bị lộ nếu xảy ra rò rỉ hay hack, dù ông công nhận đồ chơi AI có thể giúp học ngôn ngữ và phát triển giao tiếp.

(Theo CNN)